#!/usr/bin/env python3
"""
HanLP åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import sys
import os
from pathlib import Path

def test_hanlp_basic():
    """æµ‹è¯• HanLP åŸºæœ¬åŠŸèƒ½"""
    print("ğŸš€ HanLP åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    try:
        import hanlp
        print(f"âœ“ HanLP å¯¼å…¥æˆåŠŸ")
        print(f"âœ“ HanLP ç‰ˆæœ¬: {hanlp.__version__}")

        # æµ‹è¯•åŸºæœ¬å‘½åå®ä½“è¯†åˆ«
        text = 'äºŒå¨˜å’Œå°ç„¶åœ¨è¡—ä¸Šè¯´è¯ï¼Œå°æ˜è¯´ï¼š"ä½ å¥½å•Šï¼"'
        print(f"\nğŸ“ æµ‹è¯•æ–‡æœ¬: {text}")

        # åŠ è½½ NER æ¨¡å‹
        print("\nğŸ”„ æ­£åœ¨åŠ è½½ MSRA NER ALBERT æ¨¡å‹...")
        try:
            HanLP = hanlp.load(hanlp.pretrained.ner.MSRA_NER_ALBERT_BASE_ZH)
            print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")

            # è¿›è¡Œå‘½åå®ä½“è¯†åˆ«
            result = HanLP(text)
            print(f"\nğŸ¯ NER ç»“æœç±»å‹: {type(result)}")
            print(f"ğŸ¯ NER ç»“æœ: {result}")

            # æå–äººå
            names = []
            if isinstance(result, dict) and 'ner' in result:
                entities = result['ner']
                for entity in entities:
                    if isinstance(entity, (list, tuple)) and len(entity) >= 3:
                        name, entity_type, confidence = entity[:3]
                        if entity_type == 'PER' and confidence > 0.5:
                            names.append(name)
            elif isinstance(result, list):
                # å¤„ç†åˆ—è¡¨æ ¼å¼çš„ç»“æœ
                for entity in result:
                    if isinstance(entity, (list, tuple)) and len(entity) >= 3:
                        name, entity_type, confidence = entity[:3]
                        if entity_type == 'PER' and confidence > 0.5:
                            names.append(name)

            print(f"\nğŸ‘¤ è¯†åˆ«åˆ°çš„äººå: {names}")
            print("âœ“ HanLP è§’è‰²è¯†åˆ«åŠŸèƒ½æ­£å¸¸")
            return True

        except Exception as model_error:
            print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {model_error}")
            print("ğŸ”„ å°è¯•ä½¿ç”¨ç®€åŒ–ç‰ˆæ¨¡å‹...")

            # å°è¯•ä½¿ç”¨ç®€åŒ–ç‰ˆæ¨¡å‹
            try:
                HanLP = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)
                print("âœ“ ç®€åŒ–ç‰ˆæ¨¡å‹åŠ è½½æˆåŠŸ")

                result = HanLP(text)
                print(f"ğŸ¯ ç®€åŒ–ç‰ˆ NER ç»“æœ: {result}")

                names = []
                if isinstance(result, dict) and 'ner' in result:
                    entities = result['ner']
                    for entity in entities:
                        if isinstance(entity, (list, tuple)) and len(entity) >= 3:
                            name, entity_type, confidence = entity[:3]
                            if entity_type == 'PER' and confidence > 0.5:
                                names.append(name)

                print(f"\nğŸ‘¤ è¯†åˆ«åˆ°çš„äººå: {names}")
                print("âœ“ HanLP ç®€åŒ–ç‰ˆè§’è‰²è¯†åˆ«åŠŸèƒ½æ­£å¸¸")
                return True

            except Exception as fallback_error:
                print(f"âŒ ç®€åŒ–ç‰ˆæ¨¡å‹ä¹Ÿå¤±è´¥: {fallback_error}")
                return False

    except ImportError as import_error:
        print(f"âŒ HanLP å¯¼å…¥å¤±è´¥: {import_error}")
        return False
    except Exception as general_error:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {general_error}")
        return False

def test_with_local_data():
    """ä½¿ç”¨æœ¬åœ°æ•°æ®è¿›è¡Œæµ‹è¯•"""
    print("\n" + "=" * 60)
    print("ğŸ“– ä½¿ç”¨æœ¬åœ°æ•°æ®æµ‹è¯•")
    print("=" * 60)

    # æ£€æŸ¥ 1.txt æ–‡ä»¶
    data_file = Path('/app/workspace/1.txt')
    if not data_file.exists():
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return False

    try:
        with open(data_file, 'r', encoding='utf-8') as f:
            text = f.read()

        print(f"âœ“ æˆåŠŸè¯»å–æ–‡ä»¶: {data_file}")
        print(f"ğŸ“Š æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        print(f"ğŸ“Š æ–‡æœ¬é¢„è§ˆ: {text[:200]}...")

        # ä½¿ç”¨ HanLP è¿›è¡Œè§’è‰²è¯†åˆ«
        import hanlp
        print("\nğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹è¿›è¡Œè§’è‰²è¯†åˆ«...")

        try:
            HanLP = hanlp.load(hanlp.pretrained.ner.MSRA_NER_ALBERT_BASE_ZH)
        except:
            HanLP = hanlp.load(hanlp.pretrained.ner.MSRA_NER_BERT_BASE_ZH)

        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆï¼Œå¼€å§‹è¯†åˆ«...")

        # åˆ†æ‰¹å¤„ç†é•¿æ–‡æœ¬
        max_length = 512
        text_chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]

        all_names = {}
        for i, chunk in enumerate(text_chunks):
            try:
                result = HanLP(chunk)

                # æå–äººå
                if isinstance(result, dict) and 'ner' in result:
                    entities = result['ner']
                    for entity in entities:
                        if isinstance(entity, (list, tuple)) and len(entity) >= 3:
                            name, entity_type, confidence = entity[:3]
                            if entity_type == 'PER' and confidence > 0.5:
                                all_names[name] = all_names.get(name, 0) + 1
                elif isinstance(result, list):
                    for entity in result:
                        if isinstance(entity, (list, tuple)) and len(entity) >= 3:
                            name, entity_type, confidence = entity[:3]
                            if entity_type == 'PER' and confidence > 0.5:
                                all_names[name] = all_names.get(name, 0) + 1

                print(f"âœ“ å¤„ç†è¿›åº¦: {i+1}/{len(text_chunks)} ({((i+1)/len(text_chunks)*100):.1f}%)")

            except Exception as chunk_error:
                print(f"âš ï¸ å¤„ç†ç¬¬ {i+1} å—æ–‡æœ¬æ—¶å‡ºé”™: {chunk_error}")
                continue

        # æ’åºå¹¶æ˜¾ç¤ºç»“æœ
        sorted_names = sorted(all_names.items(), key=lambda x: x[1], reverse=True)

        print(f"\nâœ… è§’è‰²è¯†åˆ«å®Œæˆï¼")
        print(f"ğŸ“Š æ€»å…±è¯†åˆ«åˆ° {len(sorted_names)} ä¸ªè§’è‰²:")

        for i, (name, count) in enumerate(sorted_names[:20], 1):  # åªæ˜¾ç¤ºå‰ 20 ä¸ª
            importance = "é«˜" if count > 10 else "ä¸­" if count > 3 else "ä½"
            print(f"  {i:2d}. {name:10s} ({count:3d}æ¬¡) - {importance}")

        # ä¿å­˜ç»“æœ
        import json
        results = [
            {
                "name": name,
                "aliases": [],
                "appearance_count": count,
                "importance": "é«˜" if count > 10 else "ä¸­" if count > 3 else "ä½"
            }
            for name, count in sorted_names if count >= 2
        ]

        result_file = '/app/workspace/hanlp_recognition_result.json'
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

        # ä¸ç›®æ ‡ç»“æœå¯¹æ¯”
        target_file = Path('/app/workspace/characters.txt')
        if target_file.exists():
            print(f"\nğŸ“‹ ä¸ç›®æ ‡ç»“æœå¯¹æ¯”...")
            try:
                with open(target_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if content.strip().startswith('['):
                        target_chars = json.loads(content)
                        target_names = {char['name']: char for char in target_chars}

                        detected_names = {char['name'] for char in results}
                        target_set = set(target_names.keys())

                        print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
                        print(f"  æ£€æµ‹åˆ°è§’è‰²æ•°: {len(detected_names)}")
                        print(f"  ç›®æ ‡è§’è‰²æ•°: {len(target_set)}")
                        print(f"  é‡å è§’è‰²æ•°: {len(detected_names & target_set)}")
                        print(f"  æ£€æµ‹å‡†ç¡®ç‡: {len(detected_names & target_set) / max(len(target_set), 1) * 100:.1f}%")

                        correct_names = detected_names & target_set
                        missed_names = target_set - detected_names
                        extra_names = detected_names - target_set

                        if correct_names:
                            print(f"\nâœ… æ­£ç¡®è¯†åˆ«çš„è§’è‰² ({len(correct_names)}):")
                            for name in sorted(correct_names):
                                print(f"  â€¢ {name}")

                        if missed_names:
                            print(f"\nâŒ é—æ¼çš„è§’è‰² ({len(missed_names)}):")
                            for name in sorted(missed_names):
                                print(f"  â€¢ {name}")

                        if extra_names:
                            print(f"\nğŸ” è¯¯è¯†åˆ«çš„è§’è‰² ({len(extra_names)}):")
                            for name in sorted(extra_names)[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                                print(f"  â€¢ {name}")

            except Exception as compare_error:
                print(f"âš ï¸ å¯¹æ¯”åˆ†æå¤±è´¥: {compare_error}")

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹ HanLP åŠŸèƒ½æµ‹è¯•...")

    # åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    basic_success = test_hanlp_basic()

    if basic_success:
        print("\nğŸ‰ åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")

        # æœ¬åœ°æ•°æ®æµ‹è¯•
        local_success = test_with_local_data()

        if local_success:
            print("\nğŸ‰ æœ¬åœ°æ•°æ®æµ‹è¯•å®Œæˆï¼")
            print("\nğŸ† æ‰€æœ‰æµ‹è¯•éƒ½æˆåŠŸå®Œæˆï¼")
        else:
            print("\nâš ï¸ æœ¬åœ°æ•°æ®æµ‹è¯•å¤±è´¥")
    else:
        print("\nâŒ åŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥")
        print("âš ï¸ è·³è¿‡æœ¬åœ°æ•°æ®æµ‹è¯•")

if __name__ == "__main__":
    main()